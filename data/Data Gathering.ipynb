{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Gathering\n",
    "This notebook uses the genius API to import json files of 20 albums (10 pop, 10 hyperpop), then creates a text file with a string from the lyrics of each album. The block in the notebook defines \"get stripped lyrics\", which creates the json file and turns it into a text file with section markers stripped out. The second code block utilizes this function to create the corpus. While using the Genius API there were multiple timeout errors, so I implemented code to prevent this from breaking the creation of the corpus.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "%run functions.ipynb\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import requests\n",
    "import random\n",
    "from bs4 import BeautifulSoup\n",
    "import lyricsgenius\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stripped_lyrics(album, hyperpop=False):\n",
    "    f = open('Lyrics_' + album.replace(\" \", \"\") + '.json')\n",
    "    album_dict = json.load(f)\n",
    "    stripped_dict = ''\n",
    "    for track in album_dict['tracks']:\n",
    "        stripped_dict += strip_section_markers(track['song']['lyrics'])\n",
    "    \n",
    "    text_file = None\n",
    "    if hyperpop == False:\n",
    "        text_file = open('pop/' + album + '_lyrics_stripped.txt', 'w')\n",
    "    else:\n",
    "        text_file = open('hyperpop/' + album + '_lyrics_stripped.txt', 'w')\n",
    "    \n",
    "    text_file.write(stripped_dict)\n",
    "    text_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for \"When we all fall asleep where do we go\" by Billie Eilish...\n",
      "Wrote Lyrics_WHENWEALLFALLASLEEPWHEREDOWEGO.json.\n",
      "Searching for \"Thank U Next\" by Ariana Grande...\n",
      "Wrote Lyrics_thankunext.json.\n",
      "Searching for \"Cuz I love you\" by Lizzo...\n",
      "Wrote Lyrics_CuzILoveYou.json.\n",
      "Searching for \"Igor\" by Tyler the Creator...\n",
      "Wrote Lyrics_IGOR.json.\n",
      "Searching for \"Norman Fucking Rockwell\" by Lana Del Rey...\n",
      "Wrote Lyrics_NormanFuckingRockwell.json.\n",
      "Searching for \"Lover\" by Taylor Swift...\n",
      "Wrote Lyrics_Lover.json.\n",
      "Searching for \"Future Nostalgia\" by Dua Lipa...\n",
      "Wrote Lyrics_FutureNostalgia.json.\n",
      "Searching for \"Chromatica\" by Lady Gaga...\n",
      "Wrote Lyrics_Chromatica.json.\n",
      "Searching for \"Beauty behind the madness\" by the weeknd...\n",
      "Wrote Lyrics_BeautyBehindtheMadness.json.\n",
      "Searching for \"divide\" by ed sheeran...\n",
      "Wrote Lyrics_Divide.json.\n",
      "Searching for \"Charli\" by Charli XCX...\n",
      "Wrote Lyrics_Charli.json.\n",
      "Searching for \"1000gecs\" by 100 gecs...\n",
      "Wrote Lyrics_1000gecs.json.\n",
      "Searching for \"Apple\" by A. G. Cook...\n",
      "Wrote Lyrics_Apple.json.\n",
      "Searching for \"Flamboyant\" by Dorian Electra...\n",
      "Wrote Lyrics_Flamboyant.json.\n",
      "Searching for \"Alias\" by Shygirl...\n",
      "Wrote Lyrics_ALIAS.json.\n",
      "Searching for \"Slayyyter\" by Slayyyter...\n",
      "Wrote Lyrics_Slayyyter.json.\n",
      "Searching for \"Pang\" by Caroline Polachek...\n",
      "Wrote Lyrics_Pang.json.\n",
      "Searching for \"Reflections\" by Hannah Diamond...\n",
      "Wrote Lyrics_Reflections.json.\n",
      "Searching for \"Product\" by SOPHIE...\n",
      "Wrote Lyrics_PRODUCT.json.\n",
      "Searching for \"GFOTYBUCKS\" by GFOTY...\n",
      "Wrote Lyrics_GFOTYBUCKS.json.\n"
     ]
    }
   ],
   "source": [
    "albums = ['When we all fall asleep where do we go','Thank U Next', 'Cuz I love you', 'Igor', 'Norman Fucking Rockwell', 'Lover', 'Future Nostalgia', 'Chromatica', 'Beauty behind the madness', 'divide', 'Charli', '1000gecs', \"Apple\", \"Flamboyant\", \"Alias\", \"Slayyyter\", \"Pang\", \"Reflections\", \"Product\", \"GFOTYBUCKS\"]\n",
    "artists = ['Billie Eilish', 'Ariana Grande', 'Lizzo', 'Tyler the Creator', 'Lana Del Rey', 'Taylor Swift', 'Dua Lipa', 'Lady Gaga', 'the weeknd', 'ed sheeran', 'Charli XCX', '100 gecs', \"A. G. Cook\", \"Dorian Electra\", \"Shygirl\", \"Slayyyter\", \"Caroline Polachek\", \"Hannah Diamond\", \"SOPHIE\", \"GFOTY\"]\n",
    "HYPERPOP_INDEX = 10 #Hyper pop albums start at index 10 in the list.\n",
    "MY_CLIENT_ACCESS_TOKEN='4jBeP4S_zq8vSE_JSlu1RaJWtb6X0166lJsAFugII4IzUzOuigziDSkUFVlATdOK'\n",
    "genius = lyricsgenius.Genius(MY_CLIENT_ACCESS_TOKEN)\n",
    "\n",
    "MAX_TIMEOUTS = 5\n",
    "\n",
    "for index in range(0, len(albums)):\n",
    "    timeouts = 0\n",
    "    while True:\n",
    "        try:\n",
    "            album = genius.search_album(albums[index], artists[index])\n",
    "            album.save_lyrics()\n",
    "            break\n",
    "        except:\n",
    "            if (timeouts == MAX_TIMEOUTS):\n",
    "                print(\"Too many timeouts, something wrong with internet.\")\n",
    "                break  \n",
    "            timeouts += 1\n",
    "            \n",
    "    if index >= HYPERPOP_INDEX:\n",
    "        get_stripped_lyrics(albums[index], True)\n",
    "    else:\n",
    "        get_stripped_lyrics(albums[index])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
